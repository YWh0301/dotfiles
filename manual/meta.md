# GNU/Linux相关笔记

## 关于我自己的Linux系统的哲学

### 干净 vs 可用

在一个自己可控的系统中追求干净是无可厚非的。因为干净的系统可以使用较少的规则规定系统中的一切，因此我掌控整个系统的时候付出的记忆上的努力便可以较为轻松。然而，这是一个非常理想的情况，因为较少的规则与现代庞大的系统工程实践的现状是相违背的。这并非说系统开发者和应用开发者们都无法和他人进行有效的沟通合作，因为许多时候阻碍人们在规范上进行统一的并不是沟通的能力，而是时间。技术的发展并不真的有什么时间上的余裕，新的需求的发生与新的硬件的发明总是轮流催促软件系统的开发者，导致许多技术平台尚未完善而已经过时。这使得即便是有着极其先进哲学的GNU/Linux这一庞大社区体系中也充斥这各种过时的规范以及杂乱的构建。

在此之上强求干净并无意义。因为我的电脑的最终目的是使用，而不是作为艺术品观赏把玩。更何况在其中把握平衡的很多琐碎的工作其实是由发行版开发人员已经帮忙梳理一遍的，如果真的要事事亲力亲为，其复杂性还会比表面上能看到的要多好几倍。从某种程度上说，如果我需要快速尝试不同的东西，就必须要为了可用性而接受许多软件包的黑盒状态，接受并且欢迎它们可能在我的系统中拉屎，在各处堆放资源与配置、生成进程与服务。

但如果完全地放手，Linux的意义又不存在了。我不希望放弃对于自己的设备的掌控。这是一个永恒的矛盾，而现实就是，并不存在任何银弹方案。Nix显然不是。为了使用软件包而必须先学习一门专用的配置语言是有一些荒谬性在其中的，而其目的又仅仅是“获得可以复现的机器状态”，但我一年会重装几次机器呢？这从付出和收获的两头考虑都有点过于偏执了。

所以我的答案是，我需要为自己维护一个系统文档。我不需要自动化的安装脚本，因为实现这个脚本会有过多的细节要处理，但我需要一个文档来保存信息。在进一步的考虑中我意识到，我所需求的干净的真正含义其实并不是完全的规整或是强迫症般的洁癖，而是在不可避免的熵增中找到信息压缩的方式，并且让实际上有价值的信息并不流失。换句话说，我并不真的介意一个用了十年的机器中有各种各样的屎存在——如果我想要快乐地以各种新的方式使用我的机器而不能做到在一开始就对自己的所有工作流完全确定且永不改变，那这就是不可避免的。但是，我希望我的这个机器的状态可以被重塑，也即，如果我处于某种理由需要重装系统，而我只有这一台电脑，那么我能否把我的所有工作流与设置保存下来。

现阶段我重装机器都需要两台电脑。新的机器中的配置文件需要从老的电脑中一点一点复制过去，如果我没有另外一台电脑，我的配置和工作流就会丢失。不过，对于重要的文件我已经可以胸有成竹地说我不再担心我的电脑上的系统崩溃了，因为使用了同步云存储，所有我的重要的文件都经由pCloud同步，我购买了它永久的1T储存容量。仅存在本地的文件都是我并不在乎丢失与否的文件。而除了文件之外，还有的就是包管理、软件包和具体软件包的系统配置文件和用户态配置文件的问题。对于前三者，我打算使用文档记录的方式来保留我的配置的信息，而对于用户态配置，我使用chezmoi配合Github上的私人仓库进行保存。

由此实现的在不断熵增的系统中的重点信息保留的能力，使得我即便重装系统，也应该可以靠文档和云文件、配置文件仓库等功能实现系统复现。这样，我认为“干净”的目的其实已经达到。因为干净本身不是最终的目的，尤其如前文所述在快速与高效的使用中，干净并不可能；干净带来的可控、可重建才是目的。可重建并不需要脚本化，保障信息的留存即可。

### 可重建目标下的系统包管理思维

包管理可以说是Linux系统使用中的一个核心的问题。甚至于可以说，Linux从一个内核到一个可用的发行版之间的过程就是一个合理的包管理方式。对于每个发行版，其包管理哲学往往是最能表现其个性的地方，但在实际使用中，用户又实际上不可能严格遵循完美的包管理设计。举例而言，在使用Wine或者rust与python编程时，往往需要不同版本的Wine环境、不同的rust编译器和不同的python环境，如果全部使用Arch Linux的滚动更新的包，则许多实际应用不能实现。此时，所使用的bottles、rustup、uv就是实际意义上的包管理器，只是它们在用户空间存储可执行文件。在用户空间管理可执行文件其实十分丑陋，但是对于现代系统的容器与沙箱需求而言，针对特定应用的专门包管理是有意义的，而只有在用户空间中可以实现这样的自由（换句话说，FHS的设计其实已经过时，从某种程度上Android与Nix才是真正的现代系统；但是同代诞生的snap与AppImage等又在时刻提醒人们忘记了KISS的哲学会有多么令人作呕的事情发生，让人不禁还是倾向于接受传统发行版的设计）。

另外一种包管理器是软件插件管理系统，比如说zsh对应的antigen、nvim对应的lazy。其实这些插件都可以由pacman管理；不过，为了快速试验与高效调整，使用这样的包管理方式也无可厚非。

对于以上两种包管理中一不小心就会创造出弗兰肯斯坦式的操作系统的使用方式而言，我的底线是，所有包管理器本身应该被pacman管理。比如，不应该使用curl安装lazy，而应该在系统全局使用pacman的相应PKGBUILD把lazy安装到/usr/share下。antigen、bottles、uv、rustup等也一样。

### 系统重建文档结构

- `meta.md`
    - 记录关于自己的GNU/Linux系统维护的指导思想与哲学思考
    - 记录按主题分类的Linux学习笔记
- `installation.md`
    - 记录一个系统从安装到系统配置与用户配置迁移的所有步骤
    - 允许分叉，针对不同情形的系统安装编写专门的步骤，比如安装双系统/单一系统可以有不同的选择
    - 必须记录详细的命令行指令，不能仅提供Arch Wiki链接
    - 应用的系统级别配置应当记录在这里
- `packages.md`
    - 分成两部分记录系统安装的软件包
        - 我的所有linux机器基本上需要包含的基础功能软件包
        - 针对特定功能可以选择性安装的软件包
    - 同时描述软件包的功能
- `usages.md`
    - 记录不同主题的常用功能命令和使用方法
    - 不局限与软件包，比如某种文件系统的相应用法

## GNU/Linux技术笔记

### GNU/Linux的基础工具链

GNU世界的基础工具链是gcc、binutils和glibc，三者绑定。glibc是GNU世界的主要C库和其他多种高级语言基础库的依赖（比如rust在linux下的default target的std库就调用了glibc功能）。同时glibc提供的用户空间标准调用又在事实上规定了根文件系统的应有的布局、线程调用和内存分配的规范等OS的基础标准，因此在编译器用于标识独特target的三元组<arch>-<vendor>-<kernel>-<os>中，往往会出现以gnu作为os配合linux的组合。

在编译工具链的过程当中，不论是为同样的系统进行自举的编译，还是为了不同系统的交叉编译，一般都遵循如下顺序：

1. 编译binutils
2. 编译stage1 gcc，此处的gcc只用作基础的编译器
3. 使用stage1 gcc编译libc
4. 链接libc中的函数编译stage2 gcc，此处的gcc除了基础的编译器，还提供libgcc、libstdc++等运行在目标机器上的依赖libc的为gcc提供特性支持的语言运行时库，和记录了libc以及动态链接器的硬性位置的gcc specs

可见，完全体的gcc不仅仅包含了基础的编译器二进制程序，还包含了依赖libc的库和specs，而libc又依赖gcc的编译。依靠这种两步编译gcc的bootstrap编译法可以解决这种循环依赖的问题。此后，该gcc就和一并生产的libc绑定，如果需要为libc位置、版本或各方面细节有差异的机器编译程序，就不宜使用这个gcc，而应通过某种方式的交叉编译流程进行。

gcc、glibc、binutils项目的代码使用GNU Autoconf工具组织，其编译流程一般是`./conficure`脚本配置编译选项并自动生成Makefile，而后运行`make -j$(nproc)`进行编译。Autoconf工具依赖Posix Shell（且/bin/sh应指向一个POSIX shell）和m4工具。

### 交叉编译

交叉编译的概念不仅仅用于不同架构、不同芯片生产商的机器互相编译程序，也适用于kernel和os层面差异的机器互相之间编译的过程。换句话说，运行编译器的机器（host）的三元组<arch>-<vendor>-<kernel>-<os>与运行产物的机器（target）的三元组有任意方面的不同（os的差异由libc的差异决定，包括版本、安装位置等方面的差异），均应该通过交叉编译流程来编译程序。

交叉编译的第一步是构建交叉编译器。构建交叉编译器的过程本质上就是构建编译工具链的过程。这一过程本身也可能是交叉的，即构建交叉编译器的机器（build）和运行交叉编译器的机器（host）不一定三元组一致，最终导致build、host、target均不同的情况出现。但不论如何，编译工具链的四步法本身都是适用的，只是需要明确build机器上运行的交叉工具链为host机器编译了binutils、stage1 gcc后，需要将两者移到host机器上编译运行在target上的libc，最后将libc产物带回build机器上构建stage2 gcc。

### 内核

Linux内核项目分为两个主要仓库，即一般称作mainstream的[linux仓库](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git)和一般称作stable的[linux-stable仓库](https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git)。同时，在github.com上存在自动同步的[镜像](https://github.com/torvalds/linux)。stable仓库保留Linux的长期支持（LTS）版本分支，并将安全更新backport到LTS版本中；而所有的开发活动均在主线Linux上进行。

使用`git clone --depth 1 https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git`命令可以克隆最新的内核代码。内核代码中的Documentation文件夹内包含了同步的内核文档，可以本地访问，也可以经由[网页文档](https://www.kernel.org/doc/html/latest/)在线浏览。通过阅读Linux项目的`README`，可以获得开始阅读文档的指南。

#### 内核代码仓库与发布节奏

**mainstream**仓库中有且仅有一个`master`分支（使用`git ls-remote --heads https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git`验证），由Linus Torvalds本人维护。Linus之下有各个子系统维护者，再下方还有多层的中间维护者，每个人均有一个单独的仓库，并由维护者负责定期从mainstream仓库中fetch（保障merge base和最新的tag一致）。根据Linux的发布节奏，Linus每9到10周会对新版本的Linux在其仓库的唯一分支中打上如`v6.12`的tag，并且在该版本tag打上之后立即进行为期两周的下一个版本`v6.13`的合并窗口。在合并窗口期间，所有维护者统一进行新功能向上提交与合并的新版本准备工作（一般下层维护者在第一周完成向上层提交的工作），两周后合并窗口关闭，Linux打上下一个版本第一个rc版本`v6.13-rc1`标签。此后7到8周按照每周一个rc版本的进度发布新版本的预览版本，期间不再接受新功能的提交。rc版本迭代的7到8周内，Linus一般周一到周三接受包括关键bug修复、回归修复、文档更新在内的更新，周四至周五测试代码，并于周日发布rc版本。

Linux的维护者合之间合并代码的方式是在不同的维护者仓库之间通过request-pull请求和pull的方式进行合并（对于紧急情况也会使用patch），而开发者向维护者提交代码的方式则是向维护者发送包含代码更改的patch补丁，并由维护者手动应用（开发者提交patch并不受到合并窗口的限制，所有patch由维护者总结并等到合并窗口一并提交）。开发者patch应当根据patch修改的内容和影响范围决定自己的patch base是子系统的next分支、子系统的稳定分支，或是linux稳定版本分支，以方便维护者的合并工作。开发者、维护者之间的沟通通过邮件列表进行。

**stable**仓库中会为每一个`<major>.<minor>`版本的发布tag创建单独分支（使用`git ls-remote --heads https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git`验证），并且在这个版本还是LTS版本的时间内，为该版本提供新的安全更新。更新之后会对分支添加修订号tag`v<major>.<minor>.<revision>`（例如使用`git ls-remote --tags https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git | grep "refs/tags/v6.1\."`查看6.1版本的修订发布）。一般各大发行版从stable仓库中拉取代码编译使用。

#### 编译内核

[官方编译指南](https://www.kernel.org/doc/html/latest/admin-guide/quickly-build-trimmed-linux.html)可以在线阅读。在Arch Linux平台下，编译内核所可能需要的工具包括`base-devel bc bison cpio flex git kmod libelf openssl pahole perl bzip2 gzip lz4 lzop xz zstd ncurses qt5-tools`。

内核通过专门的Kbuild构建系统组织项目。Kbuild 的核心是一套用GNU Make语法编写的、高度递归的Makefile框架，在执行时，会调用POSIX Shell来运行命令，并依赖Perl、Python等脚本语言来处理复杂的代码生成和配置转换（例如生成头文件、解析数据结构）。此外，构建某些内核部分（如词法分析）还需要Bison和Flex等编译工具。[文档](https://www.kernel.org/doc/html/latest/kbuild/makefiles.html)中含有一些内核构建系统的信息。

内核编译的配置文件在项目文件夹下的`.config`。该文件可以用内核构建系统中的多种方式手动设置，也可以用于传播编译选项。当取用老版本内核的配置文件时，需要准备好`.config`文件之后运行`make olddefconfig`继承原有配置，并对新老版本配置选项的差异做出自动更正；也可以进一步使用`make menuconfig`检查。当`.config`配置文件准备完成后，可以使用`make -j$(nproc)`进行编译。注意，交叉编译时需要对所有make相关步骤设置环境变量`ARCH`与`CROSS_COMPILE`，如`ARCH=arm64`与`CROSS_COMPILE=aarch64-linux-gnu-`。

### 网络配置

### 键盘映射：从键码到输入

#### 内核与console

#### X与wayland

### Linux图形显示

### Linux IPC：内核功能与用户态服务

### Linux权限管理的历史

